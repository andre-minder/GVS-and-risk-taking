adujusted_average_pumps_weighted_sd = weighted_sd(adjusted_mean_pumps, n_valid_trials_BART, na.rm = TRUE))
View(BART_data_processed_generic_effect)
BART_data_processed_generic_effect <- BART_data_processed_after_exclusion|>
select("subject", "stimulation_BART", "adjusted_mean_pumps", "n_valid_trials_BART") |>
group_by(stimulation_BART) |>
summarize(adjusted_average_pumps_weighted_mean = weighted.mean(adjusted_mean_pumps, n_valid_trials_BART, na.rm = TRUE),
adujusted_average_pumps_weighted_sd = weighted_sd(adjusted_mean_pumps, n_valid_trials_BART, na.rm = TRUE)) |>
pivot_wider(names_from = "stimulation_BART", values_from = "adjusted_average_pumps_weighted"
)
BART_data_processed_generic_effect <- BART_data_processed_after_exclusion|>
select("subject", "stimulation_BART", "adjusted_mean_pumps", "n_valid_trials_BART") |>
group_by(stimulation_BART) |>
summarize(adjusted_average_pumps_weighted_mean = weighted.mean(adjusted_mean_pumps, n_valid_trials_BART, na.rm = TRUE),
adujusted_average_pumps_weighted_sd = weighted_sd(adjusted_mean_pumps, n_valid_trials_BART, na.rm = TRUE)) |>
pivot_wider(names_from = "stimulation_BART", values_from = "adjusted_average_pumps_weighted_mean")
View(BART_data_processed_generic_effect)
BART_data_processed_generic_effect <- BART_data_processed_after_exclusion|>
select("subject", "stimulation_BART", "adjusted_mean_pumps", "n_valid_trials_BART") |>
group_by(stimulation_BART) |>
summarize(adjusted_average_pumps_weighted_mean = weighted.mean(adjusted_mean_pumps, n_valid_trials_BART, na.rm = TRUE),
adujusted_average_pumps_weighted_sd = weighted_sd(adjusted_mean_pumps, n_valid_trials_BART, na.rm = TRUE))
View(BART_data_processed_generic_effect)
sum_values <- sum(BART_data_processed_generic_effect$adjusted_average_pumps_weighted_mean[1:2])
generic_effect_mean <- sum(BART_data_processed_generic_effect$adjusted_average_pumps_weighted_sd[1:2]) / 2
generic_effect_mean <- sum(BART_data_processed_generic_effect$adjusted_average_pumps_weighted_mean[1:2]) / 2
generic_effect_sd <- sum(BART_data_processed_generic_effect$adjusted_average_pumps_weighted_sd[1:2]) / 2
generic_effect_sd <- sum(BART_data_processed_generic_effect$adujusted_average_pumps_weighted_sd[1:2]) / 2
BART_data_processed_generic_effect |>
rbind(generic_effect_mean)
generic_effect <- data.frame("GenericEffect", generic_effect_mean, generic_effect_sd)
BART_data_processed_generic_effect |>
rbind(generic_effect)
generic_effect <- data.frame("GenericEffect", generic_effect_mean, generic_effect_sd)
BART_data_processed_generic_effect |>
rbind(generic_effect)
View(generic_effect)
BART_data_processed_generic_effect |>
bind_rows(generic_effect)
# A bit of data wrangling to get the generic vestibular effect (L-GVS + R-GVS / 2)
data_processed_generic_effect <- data_processed |>
select("subject", "stimulation", "adjusted_mean_pumps") |>
pivot_wider(names_from = "stimulation", values_from = "adjusted_mean_pumps") |>
rowwise() |>
mutate(generic_effect = sum(`L-GVS`, `R-GVS`, na.rm = TRUE) / 2) |>
pivot_longer(cols = -subject, names_to = "stimulation", values_to = "adjusted_mean_pumps")
# A bit of data wrangling to get the generic vestibular effect (L-GVS + R-GVS / 2)
BART_data_processed_generic_effect <- BART_data_processed |>
select("subject", "stimulation", "adjusted_mean_pumps") |>
pivot_wider(names_from = "stimulation", values_from = "adjusted_mean_pumps") |>
rowwise() |>
mutate(generic_effect = sum(`L-GVS`, `R-GVS`, na.rm = TRUE) / 2) |>
pivot_longer(cols = -subject, names_to = "stimulation", values_to = "adjusted_mean_pumps")
# A bit of data wrangling to get the generic vestibular effect (L-GVS + R-GVS / 2)
BART_data_processed_generic_effect <- BART_data_processed |>
select("subject", "stimulation_BART", "adjusted_mean_pumps") |>
pivot_wider(names_from = "stimulation_GDT", values_from = "adjusted_mean_pumps") |>
rowwise() |>
mutate(generic_effect = sum(`L-GVS`, `R-GVS`, na.rm = TRUE) / 2) |>
pivot_longer(cols = -subject, names_to = "stimulation", values_to = "adjusted_mean_pumps")
# A bit of data wrangling to get the generic vestibular effect (L-GVS + R-GVS / 2)
BART_data_processed_generic_effect <- BART_data_processed |>
select("subject", "stimulation_BART", "adjusted_mean_pumps") |>
pivot_wider(names_from = "stimulation_BART", values_from = "adjusted_mean_pumps") |>
rowwise() |>
mutate(generic_effect = sum(`L-GVS`, `R-GVS`, na.rm = TRUE) / 2) |>
pivot_longer(cols = -subject, names_to = "stimulation", values_to = "adjusted_mean_pumps")
# Get the descriptives for the stimulation effects in a nicely printed table
data_processed_generic_effect |>
group_by(stimulation) |>
summarise(Mean = round_half_up(mean(adjusted_mean_pumps), 2),
SD = round_half_up(sd(adjusted_mean_pumps), 2)) |>
kable() |>
kable_classic(full_width = FALSE)
# Get the descriptive statistics for the stimulation effects in a nicely printed table
data_processed_generic_effect |>
group_by(stimulation) |>
summarise(Mean = round_half_up(mean(adjusted_mean_pumps), 2),
SD = round_half_up(sd(adjusted_mean_pumps), 2)) |>
kable() |>
kable_classic(full_width = FALSE)
# Get the descriptive statistics for the stimulation effects in a nicely printed table
data_processed_generic_effect |>
group_by(stimulation_BART) |>
summarise(Mean = round_half_up(mean(adjusted_mean_pumps), 2),
SD = round_half_up(sd(adjusted_mean_pumps), 2)) |>
kable() |>
kable_classic(full_width = FALSE)
# Get the descriptive statistics for the stimulation effects in a nicely printed table
BART_data_processed_generic_effect |>
group_by(stimulation_BART) |>
summarise(Mean = round_half_up(mean(adjusted_mean_pumps), 2),
SD = round_half_up(sd(adjusted_mean_pumps), 2)) |>
kable() |>
kable_classic(full_width = FALSE)
View(BART_data_processed_generic_effect)
# A bit of data wrangling to get the generic vestibular effect (L-GVS + R-GVS / 2)
BART_data_processed_generic_effect <- BART_data_processed_after_exclusion |>
select("subject", "stimulation_BART", "adjusted_mean_pumps") |>
pivot_wider(names_from = "stimulation_BART", values_from = "adjusted_mean_pumps") |>
rowwise() |>
mutate(generic_effect = sum(`L-GVS`, `R-GVS`, na.rm = TRUE) / 2) |>
pivot_longer(cols = -subject, names_to = "stimulation", values_to = "adjusted_mean_pumps")
# Get the descriptive statistics for the stimulation effects in a nicely printed table
BART_data_processed_generic_effect |>
group_by(stimulation_BART) |>
summarise(Mean = round_half_up(mean(adjusted_mean_pumps), 2),
SD = round_half_up(sd(adjusted_mean_pumps), 2)) |>
kable() |>
kable_classic(full_width = FALSE)
View(BART_data_processed_generic_effect)
# A bit of data wrangling to get the generic vestibular effect (L-GVS + R-GVS / 2)
BART_data_processed_generic_effect <- BART_data_processed_after_exclusion |>
select("subject", "stimulation_BART", "adjusted_mean_pumps") |>
pivot_wider(names_from = "stimulation_BART", values_from = "adjusted_mean_pumps") |>
rowwise() |>
mutate(generic_effect = sum(`L-GVS`, `R-GVS`, na.rm = TRUE) / 2) |>
pivot_longer(cols = -subject, names_to = "stimulation_BART", values_to = "adjusted_mean_pumps")
# Get the descriptive statistics for the stimulation effects in a nicely printed table
BART_data_processed_generic_effect |>
group_by(stimulation_BART) |>
summarise(Mean = round_half_up(mean(adjusted_mean_pumps), 2),
SD = round_half_up(sd(adjusted_mean_pumps), 2)) |>
kable() |>
kable_classic(full_width = FALSE)
View(BART_data_processed_after_exclusion)
BART_data_processed_exploded_balloons <- BART_data_processed_after_exclusion |>
group_by(stimulation) |>
summarize(proportion_exploded_balloons_mean = mean(proportion_exploded_balloons, na.rm = TRUE),
proportion_exploded_balloons_sd = sd(proportion_exploded_balloons, na.rm = TRUE))
BART_data_processed_exploded_balloons <- BART_data_processed_after_exclusion |>
group_by(stimulation_BART) |>
summarize(proportion_exploded_balloons_mean = mean(proportion_exploded_balloons, na.rm = TRUE),
proportion_exploded_balloons_sd = sd(proportion_exploded_balloons, na.rm = TRUE))
BART_data_processed_exploded_balloons <- BART_data_processed_after_exclusion |>
group_by(stimulation_BART) |>
summarize(proportion_exploded_balloons_mean = mean(proportion_exploded_balloons, na.rm = TRUE),
proportion_exploded_balloons_sd = sd(proportion_exploded_balloons, na.rm = TRUE)) |>
kable() |>
kable_classic(full_width)
BART_data_processed_after_exclusion |>
group_by(stimulation_BART) |>
summarize(proportion_exploded_balloons_mean = mean(proportion_exploded_balloons, na.rm = TRUE),
proportion_exploded_balloons_sd = sd(proportion_exploded_balloons, na.rm = TRUE)) |>
kable() |>
kable_classic(full_width = FALSE)
proportion_exploded_balloons_sd = round_half_up(sd(proportion_exploded_balloons, na.rm = TRUE), 2) |>
BART_data_processed_after_exclusion |>
group_by(stimulation_BART) |>
summarize(proportion_exploded_balloons_mean = round_half_up(mean(proportion_exploded_balloons, na.rm = TRUE), 2),
proportion_exploded_balloons_sd = round_half_up(sd(proportion_exploded_balloons, na.rm = TRUE), 2)) |>
kable() |>
kable_classic(full_width = FALSE)
BART_data_processed_after_exclusion |>
group_by(stimulation_BART) |>
summarize(proportion_exploded_balloons_mean = round_half_up(mean(proportion_exploded_balloons, na.rm = TRUE), 2),
proportion_exploded_balloons_sd = round_half_up(sd(proportion_exploded_balloons, na.rm = TRUE), 2)) |>
kable() |>
kable_classic(full_width = FALSE)
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
# just some packages to facilited the data wrangling/tidying
library(tidyverse)
library(purrr)
library(janitor)
# read in the full condition table
condition_table <- read_csv("data/conditions/conditions_table.csv")
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
# just some packages to facilited the data wrangling/tidying
library(tidyverse)
library(purrr)
library(janitor)
# read in the full condition table
condition_table <- read_csv("conditions/conditions_table.csv")
# select only the sessions for the BART and transform the data frame into long format (this will facilitate the joining of the different data frames later on)
condition_table_BART <- condition_table |>
select("subject", starts_with("BART")) |>
rename("01" = BART_session_1, "02" = BART_session_2, "03" = BART_session_3) |>
pivot_longer(cols = -subject, names_to = "session", values_to = "stimulation")
# select only the sessions for the GDT and transform the data frame into long format (this will facilitate the joining of the different data frames later on)
condition_table_GDT <- condition_table |>
select("subject", starts_with("GDT")) |>
rename("01" = GDT_session_1, "02" = GDT_session_2, "03" = GDT_session_3) |>
pivot_longer(cols = -subject, names_to = "session", values_to = "stimulation")
# reading in the single demographics files from each participant
demo_files <- list.files(path = "data_test/", recursive = TRUE, pattern = "*demographics*")
# while reading in: transform values of the variable frameRate into a characters, because it might not be an integer due to frame drops and block the merging of the tables
demographics_raw <- map_dfr(.x = set_names(paste0("data_test/", demo_files)),
.f = ~ read_tsv(.x, col_types = cols(.default = "?", frameRate = "c")))
# Select variables age and gender. Filter out empty rows created by PsychoPy at the start and the end of the experiment.
demographics_clean <- demographics_raw |>
clean_names() |>
select(subject = participant,
age = text_age_input_text,
gender = slider_gender_response) |>
filter(!is.na(gender))
# Select variables age and gender. Filter out empty rows created by PsychoPy at the start and the end of the experiment.
demographics_clean <- demographics_raw |>
clean_names() |>
select(subject = participant,
age = text_age_input_text,
gender = slider_gender_response) |>
filter(!is.na(gender))
# Select variables age and gender. Filter out empty rows created by PsychoPy at the start and the end of the experiment.
demographics_clean <- demographics_raw |>
select(subject = participant,
age = text_age_input_text,
gender = slider_gender_response) |>
filter(!is.na(gender))
# Select variables age and gender. Filter out empty rows created by PsychoPy at the start and the end of the experiment.
demographics_clean <- demographics_raw |>
clean_names() |>
select(subject = participant,
age = text_age_input_text,
gender = slider_gender_response) |>
filter(!is.na(gender))
library(janitor)
# Select variables age and gender. Filter out empty rows created by PsychoPy at the start and the end of the experiment.
demographics_clean <- demographics_raw |>
clean_names() |>
select(subject = participant,
age = text_age_input_text,
gender = slider_gender_response) |>
filter(!is.na(gender))
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
# just some packages to facilited the data wrangling/tidying
library(tidyverse)
library(purrr)
library(janitor)
# read in the full condition table
condition_table <- read_csv("conditions/conditions_table.csv")
# select only the sessions for the BART and transform the data frame into long format (this will facilitate the joining of the different data frames later on)
condition_table_BART <- condition_table |>
select("subject", starts_with("BART")) |>
rename("01" = BART_session_1, "02" = BART_session_2, "03" = BART_session_3) |>
pivot_longer(cols = -subject, names_to = "session", values_to = "stimulation")
# select only the sessions for the GDT and transform the data frame into long format (this will facilitate the joining of the different data frames later on)
condition_table_GDT <- condition_table |>
select("subject", starts_with("GDT")) |>
rename("01" = GDT_session_1, "02" = GDT_session_2, "03" = GDT_session_3) |>
pivot_longer(cols = -subject, names_to = "session", values_to = "stimulation")
# reading in the single demographics files from each participant
demo_files <- list.files(path = "data_test/", recursive = TRUE, pattern = "*demographics*")
# while reading in: transform values of the variable frameRate into a characters, because it might not be an integer due to frame drops and block the merging of the tables
demographics_raw <- map_dfr(.x = set_names(paste0("data_test/", demo_files)),
.f = ~ read_tsv(.x, col_types = cols(.default = "?", frameRate = "c")))
# Select variables age and gender. Filter out empty rows created by PsychoPy at the start and the end of the experiment.
demographics_clean <- demographics_raw |>
clean_names() |>
select(subject = participant,
age = text_age_input_text,
gender = slider_gender_response) |>
filter(!is.na(gender))
# reading in the .tsv files from each block/session (three per participant) from each participant
BART_files <- list.files(path = "data_test/", recursive = TRUE, pattern = "*balloonanalogrisktask*")
# while reading in: again taking care of the frameRate variable (see demographics section)
BART_raw <- map_dfr(.x = set_names(paste0("data_test/", BART_files)),
.f = ~ read_tsv(.x, col_types = cols(.default = "?", frameRate = "c")))
# Select variables subject, session, n_pumps, popped, and earnings. Filter out empty rows created by PsychoPy at the start and the end of the experimental block. Join it with the conditions table.
BART_clean_with_conditions <- BART_raw |>
clean_names() |>
select(subject = participant, session, n_pumps, popped, earnings) |>
filter(!is.na(n_pumps)) |>
left_join(condition_table_BART, by = c("subject", "session"))
# marking exclusions on the trial level (first criterion)
BART_clean_with_conditions_and_exclusions_trials <- BART_clean_with_conditions |>
mutate(valid_trial = ifelse((popped == FALSE & n_pumps <= 1), FALSE, TRUE))
# marking exclusions due to invalid trials on the subject level (second criterion). Exclude participants with less than 27 valid trials from the analysis.
BART_clean_with_conditions_and_exclusions_subject_valid <- BART_clean_with_conditions_and_exclusions_trials |>
group_by(subject, session, stimulation) |>
summarize(n_valid_trials_BART = sum(valid_trial, na.rm = TRUE)) |>
mutate(fast_answer_exclusion_subject = ifelse(n_valid_trials_BART < 27, "exclude", "include"))
# Check if participants have data for all stimulation blocks (third criterion)
BART_clean_with_conditions_and_exclusions_subject_complete <- BART_clean_with_conditions_and_exclusions_subject_valid |>
group_by(subject) |>
count(stimulation) |>
pivot_wider(names_from = "stimulation", values_from = n) |>
mutate(complete_BART_data = case_when(is.na(`L-GVS`) ~ "exclude",
is.na(`R-GVS`) ~ "exclude",
is.na(SHAM) ~ "exclude",
TRUE ~ "include")) |>
select("subject", "complete_BART_data")
# Join the two subject level dfs
BART_clean_with_conditions_and_exclusions_subject <-
full_join(BART_clean_with_conditions_and_exclusions_subject_valid,
BART_clean_with_conditions_and_exclusions_subject_complete, by = "subject")
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
# apply the master exclusion to the BART data
BART_data_processed_after_exclusion <- BART_data_processed |>
filter(BART_master_exclusions == "include")
BART_data_processed <- read_csv("processed/BART_data_processed.csv")
GDT_data_processed <- read_csv("processed/GDT_data_processed.csv")
# apply the master exclusion to the BART data
BART_data_processed_after_exclusion <- BART_data_processed |>
filter(BART_master_exclusions == "include")
# apply the master exclusion to the GDT data
GDT_data_processed_after_exclusion <- GDT_data_processed |>
filter(GDT_master_exclusions == "include")
# Get the descriptive statistics for age and print them in a nice table
BART_data_processed_after_exclusion |>
mutate(age = as.numeric(age)) |>
distinct(subject, .keep_all = TRUE) |>
summarise(Mean = mean(age, na.rm = TRUE),
SD = sd(age, na.rm = TRUE)) |>
mutate_all(.funs = janitor::round_half_up, digits = 1) |>
kable() |>
add_header_above(header = c("Age" = 2)) |>
kable_classic(full_width = FALSE)
library(tidyverse)    # data wrangling
library(janitor)      # for the rounding function round_half_up()
library(easystats)    # easy report of statistics
library(TOSTER)       # for the TOST equivalence testing
library(kableExtra)   # just for printing a nice table in the HTML file
library(effsize)      # used for calculating the critical effect size (see equivalence test)
# Get the descriptive statistics for age and print them in a nice table
BART_data_processed_after_exclusion |>
mutate(age = as.numeric(age)) |>
distinct(subject, .keep_all = TRUE) |>
summarise(Mean = mean(age, na.rm = TRUE),
SD = sd(age, na.rm = TRUE)) |>
mutate_all(.funs = janitor::round_half_up, digits = 1) |>
kable() |>
add_header_above(header = c("Age" = 2)) |>
kable_classic(full_width = FALSE)
# Get the descriptives for gender and also print them in a nice table
BART_data_processed_after_exclusion |>
rename(Gender = gender) |>
distinct(subject, .keep_all = TRUE) |>
group_by(Gender) |>
summarise(n = n()) |>
mutate(Percent = paste0(round_half_up((n / sum(n)) * 100, 1), "%")) |>
mutate(Gender = stringr::str_to_sentence(Gender)) |>
kable() |>
kable_classic(full_width = FALSE)
BART_data_processed_after_exclusion |>
group_by(stimulation_BART) |>
summarize(proportion_exploded_balloons_mean = round_half_up(mean(proportion_exploded_balloons, na.rm = TRUE), 2),
proportion_exploded_balloons_sd = round_half_up(sd(proportion_exploded_balloons, na.rm = TRUE), 2)) |>
kable() |>
kable_classic(full_width = FALSE)
# A bit of data wrangling to get the generic vestibular effect (L-GVS + R-GVS / 2)
BART_data_processed_generic_effect <- BART_data_processed_after_exclusion |>
select("subject", "stimulation_BART", "adjusted_mean_pumps") |>
pivot_wider(names_from = "stimulation_BART", values_from = "adjusted_mean_pumps") |>
rowwise() |>
mutate(generic_effect = sum(`L-GVS`, `R-GVS`, na.rm = TRUE) / 2) |>
pivot_longer(cols = -subject, names_to = "stimulation_BART", values_to = "adjusted_mean_pumps")
# Get the descriptive statistics for the stimulation effects in a nicely printed table
BART_data_processed_generic_effect |>
group_by(stimulation_BART) |>
summarise(Mean = round_half_up(mean(adjusted_mean_pumps), 2),
SD = round_half_up(sd(adjusted_mean_pumps), 2)) |>
kable() |>
kable_classic(full_width = FALSE)
# Generate a table with the choices per stimulation block
GDT_data_processed_after_exclusion |>
select("subject", "stimulation_GDT", "safest", "safe", "risky", "riskiest") |>
pivot_longer(cols = safest:riskiest, names_to = "choice", values_to = "n") |>
group_by(stimulation_GDT, choice) |>
summarise(N = sum(n, na.rm = TRUE)) |>
pivot_wider(names_from = "choice", values_from = "N") |>
kable() |>
kable_classic(full_width = FALSE)
# A bit of data wrangling to get the generic vestibular effect (L-GVS + R-GVS / 2) for the GDT
GDT_data_processed_generic_effect <- GDT_data_processed_after_exclusion |>
select("subject", "stimulation_GDT", "score") |>
pivot_wider(names_from = "stimulation_GDT", values_from = "score") |>
rowwise() |>
mutate(generic_effect = sum(`L-GVS`, `R-GVS`, na.rm = TRUE) / 2) |>
pivot_longer(cols = -subject, names_to = "stimulation_GDT", values_to = "score")
# Get the descriptive stats for the stimulation effects in a nicely printed table
GDT_data_processed_generic_effect |>
group_by(stimulation_GDT) |>
summarise(Median = round_half_up(median(score), 2),
SD = round_half_up(sd(score), 2)) |>
kable() |>
kable_classic(full_width = FALSE)
BART_proportion_exploded_balloons <- BART_clean_with_conditions_and_exclusions_trials |>
group_by(stimulation) |>
summarize(proportion_exploded_balloons = mean(popped))
View(BART_proportion_exploded_balloons)
BART_proportion_exploded_balloons <- BART_clean_with_conditions_and_exclusions_trials |>
group_by(stimulation) |>
summarize(proportion_exploded_balloons = mean(popped),
sdd = sd(popped))
View(BART_proportion_exploded_balloons)
# Generate a table with the choices per stimulation block
GDT_data_processed_after_exclusion |>
select("subject", "stimulation_GDT", "safest", "safe", "risky", "riskiest") |>
pivot_longer(cols = safest:riskiest, names_to = "choice", values_to = "n") |>
group_by(stimulation_GDT, choice) |>
summarise(N = sum(n, na.rm = TRUE)) |>
pivot_wider(names_from = "choice", values_from = "N") |>
kable() |>
kable_classic(full_width = FALSE)
# Generate a table with the choices per stimulation block
GDT_data_processed_after_exclusion |>
select("subject", "stimulation_GDT", "safest", "safe", "risky", "riskiest") |>
pivot_longer(cols = safest:riskiest, names_to = "choice", values_to = "n") |>
group_by(stimulation_GDT, choice) |>
summarise(N = sum(n, na.rm = TRUE)) |>
pivot_wider(names_from = "choice", values_from = "N") |>
kable() |>
kable_classic(full_width = FALSE)
# A bit of data wrangling to get the generic vestibular effect (L-GVS + R-GVS / 2) for the GDT
GDT_data_processed_generic_effect <- GDT_data_processed_after_exclusion |>
select("subject", "stimulation_GDT", "score") |>
pivot_wider(names_from = "stimulation_GDT", values_from = "score") |>
rowwise() |>
mutate(generic_effect = sum(`L-GVS`, `R-GVS`, na.rm = TRUE) / 2) |>
pivot_longer(cols = -subject, names_to = "stimulation_GDT", values_to = "score")
# Get the descriptive stats for the stimulation effects in a nicely printed table
GDT_data_processed_generic_effect |>
group_by(stimulation_GDT) |>
summarise(Median = round_half_up(median(score), 2),
SD = round_half_up(sd(score), 2)) |>
kable() |>
kable_classic(full_width = FALSE)
# A bit of data wrangling to get the generic vestibular effect (L-GVS + R-GVS / 2) for the GDT
GDT_data_processed_generic_effect <- GDT_data_processed_after_exclusion |>
select("subject", "stimulation_GDT", "score") |>
pivot_wider(names_from = "stimulation_GDT", values_from = "score") |>
rowwise() |>
mutate(generic_effect = median(sum(`L-GVS`, `R-GVS`, na.rm = TRUE))) |>
pivot_longer(cols = -subject, names_to = "stimulation_GDT", values_to = "score")
View(GDT_data_processed_generic_effect)
# A bit of data wrangling to get the generic vestibular effect (L-GVS + R-GVS / 2) for the GDT
GDT_data_processed_generic_effect <- GDT_data_processed_after_exclusion |>
select("subject", "stimulation_GDT", "score") |>
pivot_wider(names_from = "stimulation_GDT", values_from = "score") |>
rowwise() |>
mutate(generic_effect = median(`L-GVS`, `R-GVS`, na.rm = TRUE)) |>
pivot_longer(cols = -subject, names_to = "stimulation_GDT", values_to = "score")
View(GDT_data_processed_generic_effect)
# Get the descriptive stats for the stimulation effects in a nicely printed table
GDT_data_processed_generic_effect |>
group_by(stimulation_GDT) |>
summarise(Median = round_half_up(median(score), 2),
MAD = round_half_up(mad(score), 2)) |>
kable() |>
kable_classic(full_width = FALSE)
# A bit of data wrangling to get the generic vestibular effect (L-GVS + R-GVS / 2) for the GDT
GDT_data_processed_generic_effect <- GDT_data_processed_after_exclusion |>
select("subject", "stimulation_GDT", "score") |>
pivot_wider(names_from = "stimulation_GDT", values_from = "score") |>
rowwise() |>
mutate(generic_effect = sum(`L-GVS`, `R-GVS`, na.rm = TRUE) / 2) |>
pivot_longer(cols = -subject, names_to = "stimulation_GDT", values_to = "score")
# A bit of data wrangling
data_processed_generic_effect_test_BART <- data_processed_generic_effect_BART |>
filter(stimulation != c("L-GVS", "R-GVS"))
# A bit of data wrangling
BART_data_processed_generic_effect_test <- BART_data_processed_generic_effect |>
filter(stimulation != c("L-GVS", "R-GVS"))
# A bit of data wrangling
BART_data_processed_generic_effect_test <- BART_data_processed_generic_effect |>
filter(stimulation_BART != c("L-GVS", "R-GVS"))
t.test(adjusted_mean_pumps ~ stimulation_BART, data = BART_data_processed_generic_effect_test,
paired = TRUE, alternative = "two.sided") |>
report()
# A bit of data wrangling to exclude the SHAM condition
BART_data_processed_specific_effect_test <- BART_data_processed_after_exclusion |>
filter(stimulation_BART != "SHAM")
t.test(adjusted_mean_pumps ~ stimulation_BART, data = BART_data_processed_specific_effect_test,
paired = TRUE, alternative = "two.sided") |>
report()
# get the critical t value of the original study
critical_t <- qt(p = .975, df = 19, lower.tail = TRUE)
# calculate the critical effect size (the effect size that would have just been significant in the original study)
critical_d <- t_to_d(critical_t, df = 19, paired = TRUE, alternative = "two.sided")
t_TOST(
adjusted_mean_pumps ~ stimulation,
data = data_processed_specific_effect,
hypothesis = "EQU",
paired = TRUE,
eqb = critical_d$d,
eqbound_type = "SMD",
alpha = 0.05,
)
t_TOST(
adjusted_mean_pumps ~ stimulation,
data = BART_data_processed_specific_effect,
hypothesis = "EQU",
paired = TRUE,
eqb = critical_d$d,
eqbound_type = "SMD",
alpha = 0.05,
)
t_TOST(
adjusted_mean_pumps ~ stimulation,
data = BART_data_processed_specific_effect_test,
hypothesis = "EQU",
paired = TRUE,
eqb = critical_d$d,
eqbound_type = "SMD",
alpha = 0.05,
)
t_TOST(
adjusted_mean_pumps ~ stimulation_BART,
data = BART_data_processed_specific_effect_test,
hypothesis = "EQU",
paired = TRUE,
eqb = critical_d$d,
eqbound_type = "SMD",
alpha = 0.05,
)
# calculate the critical effect size (the effect size that would have just been significant in the original study)
critical_d <- t_to_d(critical_t, df = 19, paired = TRUE, alternative = "two.sided")
critical_d
critical_d$d
